{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "585e8b5b-bcef-4a5f-8d9c-a4c820d6579c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  WARNING: The script isympy is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script pytube is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script humanfriendly is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script httpx is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script coloredlogs is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script pyproject-build is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script youtube_transcript_api is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts opentelemetry-bootstrap and opentelemetry-instrument are installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script onnxruntime_test is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script langsmith is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script huggingface-cli is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The scripts gradio and upload_theme are installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script langchain-server is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script chroma is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "kfp 2.7.0 requires kubernetes<27,>=8.0.0, but you have kubernetes 29.0.0 which is incompatible.\n",
      "kfp 2.7.0 requires urllib3<2.0.0, but you have urllib3 2.2.1 which is incompatible.\n",
      "apache-beam 2.46.0 requires protobuf<4,>3.12.2, but you have protobuf 4.25.3 which is incompatible.\n",
      "dataproc-jupyter-plugin 0.1.74 requires pydantic~=1.10.0, but you have pydantic 2.6.4 which is incompatible.\n",
      "tensorflow-transform 0.14.0 requires protobuf<4,>=3.7, but you have protobuf 4.25.3 which is incompatible.\n",
      "ydata-profiling 4.6.0 requires pydantic<2,>=1.8.1, but you have pydantic 2.6.4 which is incompatible.\n",
      "ydata-profiling 4.6.0 requires seaborn<0.13,>=0.10.1, but you have seaborn 0.13.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --user google-cloud-aiplatform>=1.29.0 google-cloud-storage langchain langchain-google-vertexai pytube youtube-transcript-api chromadb gradio pydantic\n",
    "# You may safely ignore dependency warnings below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddaff1c2-0c30-41ba-a2ac-1b6a1640b6c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restart kernel after installs so that your environment can access the new packages\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea3eafd-08be-49f1-80dc-3216f23d8996",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get project ID\n",
    "PROJECT_ID = ! gcloud config get project\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "LOCATION = \"us-central1\" # <-- Enter assigned region here.\n",
    "\n",
    "# generate an unique id for this session\n",
    "from datetime import datetime\n",
    "UID = datetime.now().strftime(\"%m%d%H%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b23f4928-e2eb-4236-9ea4-e7c75b486a21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# init the vertexai package\n",
    "from google.cloud import aiplatform\n",
    "aiplatform.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c17f158-5345-4cde-a8dd-3f3832afb478",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import YoutubeLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_google_vertexai import VertexAI\n",
    "\n",
    "llm = VertexAI(\n",
    "    model_name=\"text-bison@001\",\n",
    "    max_output_tokens=256,\n",
    "    temperature=0.1,\n",
    "    top_p=0.8,\n",
    "    top_k=40,\n",
    "    verbose=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91bf0e0f-247a-4156-93da-805255260b08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "\n",
    "# Embedding\n",
    "EMBEDDING_QPM = 100\n",
    "EMBEDDING_NUM_BATCH =5\n",
    "\n",
    "embeddings = VertexAIEmbeddings(\n",
    "    model_name=\"textembedding-gecko@001\",\n",
    "    requests_per_minute=EMBEDDING_QPM,\n",
    "    num_instances_per_batch=EMBEDDING_NUM_BATCH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2db0bc4-1e9b-4232-a3ea-718a4381957b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader = YoutubeLoader.from_youtube_url(\"https://www.youtube.com/watch?v=XX2XpqklUrE\", add_video_info=True)\n",
    "result = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79f75d17-cbf6-401b-b92b-b4e3912be9c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of documents = 4\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(result)\n",
    "print(f\"# of documents = {len(docs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d60bdba-a04f-4e7f-aca5-5eb50ef206d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 4 embeddings\n",
      "Here's a sample of one: [-0.03151746094226837, -0.042533669620752335, 0.004869665950536728]...\n"
     ]
    }
   ],
   "source": [
    "embedding_list = embeddings.embed_documents([doc.page_content for doc in docs])\n",
    "print(f\"You have {len(embedding_list)} embeddings\")\n",
    "print(f\"Here's a sample of one: {embedding_list[0][:3]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8696a92-bf4a-41d2-9570-7ae64a4c3ee7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db = Chroma.from_documents(docs, embeddings)\n",
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 2})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbdfafd0-73da-4fce-9762-31ada15185c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type( llm=llm, chain_type=\"stuff\", retriever=retriever, return_source_documents=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24bceef2-5519-40e8-8cb0-0071b8a89c1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sm_ask(question, print_results=True):\n",
    "  video_subset = qa({\"query\": question})\n",
    "  context = video_subset\n",
    "  prompt = f\"\"\"\n",
    "  Answer the following question in a detailed manner, using information from the text below. If the answer is not in the text,say I dont know and do not generate your own response.\n",
    "\n",
    "  Question:\n",
    "  {question}\n",
    "  Text:\n",
    "  {context}\n",
    "\n",
    "  Question:\n",
    "  {question}\n",
    "\n",
    "  Answer:\n",
    "  \"\"\"\n",
    "  parameters = {\n",
    "      \"temperature\": 0.1,\n",
    "      \"max_output_tokens\": 256,\n",
    "      \"top_p\": 0.8,\n",
    "      \"top_k\": 40\n",
    "  }\n",
    "  response = llm.predict(prompt, **parameters)\n",
    "  return {\n",
    "      \"answer\": response\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9165f3c-adf3-4a60-90ec-fa1b0c1cf2f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://5dee6a81c8ba2ae76f.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://5dee6a81c8ba2ae76f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `predict` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "def get_response(input_text):\n",
    "  response = sm_ask(input_text)\n",
    "  return response\n",
    "\n",
    "grapp = gr.Interface(fn=get_response, inputs=\"text\", outputs=\"text\")\n",
    "grapp.launch(share=True)\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-15.m119",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-15:m119"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
